# AI Hub - Quick Reference

## ğŸš€ Launch Commands

```bash
# TUI Management Console (Recommended)
~/Projects/ai/ai-hub

# Individual Tools
~/Projects/ai/scripts/launch-claude.sh
~/Projects/ai/scripts/launch-crush.sh
~/Projects/ai/scripts/launch-gemini.sh
~/Projects/ai/scripts/launch-ollama.sh run llama2
~/Projects/ai/scripts/launch-lmstudio.sh
~/Projects/ai/scripts/launch-qwen.sh
~/Projects/ai/scripts/launch-opencode.sh
~/Projects/ai/scripts/launch-sd-webui.sh

# Status Check
~/Projects/ai/scripts/ai-hub-status.sh
```

## ğŸ“ Directory Structure

```
~/Projects/ai/                    (31GB)
â”œâ”€â”€ ai-hub                        # TUI launcher
â”œâ”€â”€ configs/                      # Tool configs
â”‚   â”œâ”€â”€ .venv/                   # 9.2GB CUDA Python
â”‚   â””â”€â”€ .env                     # API keys
â”œâ”€â”€ workspaces/                   # Tool workspaces
â”‚   â”œâ”€â”€ claude/
â”‚   â”œâ”€â”€ ollama/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                       # Shared AI models (13GB)
â”‚   â””â”€â”€ checkpoints/             # SD checkpoints
â”œâ”€â”€ stable-diffusion-webui/      # 9.3GB
â””â”€â”€ scripts/                      # Launchers & tools
```

## ğŸ› ï¸ TUI Quick Menu

```
Main Menu:
  [1] System Information      - CPU, RAM, GPU, VRAM stats
  [2] Tool Status            - Installation & workspace status
  [3] Model Management       - View, check, cleanup models
  [4] Storage Breakdown      - Disk usage analysis
  [5] Launch Tool            - Interactive launcher
  [0] Exit
```

## ğŸ“¦ Model Requirements

| Model | RAM | VRAM | Disk |
|-------|-----|------|------|
| FLUX Dev | 16GB | 12GB | 24GB |
| SDXL | 16GB | 8GB | 7GB |
| SD 1.5 | 8GB | 4GB | 4GB |

**Your System:**
- RAM: 10GB available
- GPU: RTX 3060 (6GB VRAM)
- Disk: 100GB free

## ğŸ’¾ Storage Locations

```bash
# Models
~/Projects/ai/models/checkpoints/

# ComfyUI (symlinked to shared models)
~/Projects/comfy/ComfyUI/models/checkpoints-link

# SD-WebUI (symlinked to shared models)
~/Projects/ai/stable-diffusion-webui/models/Stable-diffusion-shared

# API Keys
~/Projects/ai/configs/.env
```

## âš¡ Quick Tasks

### Check system specs before downloading
```bash
~/Projects/ai/ai-hub
# â†’ [3] Model Management â†’ [2] Check requirements
```

### View all installed tools
```bash
~/Projects/ai/ai-hub
# â†’ [2] Tool Status
```

### Clean up old models
```bash
~/Projects/ai/ai-hub
# â†’ [3] Model Management â†’ [4] Clean up old models
```

### Check storage usage
```bash
~/Projects/ai/ai-hub
# â†’ [4] Storage Breakdown
```

### Launch Ollama with model
```bash
~/Projects/ai/scripts/launch-ollama.sh run deepseek-coder
```

## ğŸ”§ Maintenance

```bash
# Load API keys
source ~/Projects/ai/scripts/load-env.sh

# Check hub status
~/Projects/ai/scripts/ai-hub-status.sh

# Update hub setup
~/Projects/ai/scripts/setup-tool-access.sh
```

## ğŸ“Š Current Stats

- **Total Space:** 90.1GB cleaned, 31GB in use
- **Tools:** 7 AI tools configured
- **Models:** 3 SD checkpoints (13GB)
- **Workspaces:** 8 isolated environments

## ğŸ¯ Installed Tools

âœ“ Claude Code
âœ“ Crush
âœ“ Gemini
âœ“ Ollama
âœ“ LM Studio
âœ“ Qwen
âœ“ OpenCode
âœ“ SD WebUI

## ğŸ“– Documentation

- Full guide: `~/Projects/ai/README.md`
- TUI guide: `~/Projects/ai/TUI-GUIDE.md`
- Model info: `~/Projects/ai/models/README.md`

---

## ğŸ”¥ Bash Aliases (Already Added!)

The following aliases have been added to your `~/.bashrc`:

```bash
# Main TUI launcher
ai                    # Launch AI Hub TUI

# Quick commands
ai-status            # Show tool status (non-interactive)
ai-models            # List all checkpoint models
ai-env               # Load API keys into environment
```

**Usage examples:**
```bash
# Open TUI
ai

# Quick status check
ai-status

# View models
ai-models

# Load environment for manual tool launch
ai-env
ollama run deepseek-coder
```

**To activate in current session:**
```bash
source ~/.bashrc
```

**Then just type:**
```bash
ai  # That's it!
```
