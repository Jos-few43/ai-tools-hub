# AI Tools Hub

Central configuration and workspace for AI CLI tools with filesystem access.

## Directory Structure

```
~/Projects/ai/
â”œâ”€â”€ configs/               # Tool-specific configurations
â”‚   â”œâ”€â”€ .claude/          # Claude Code configs
â”‚   â”œâ”€â”€ .crush/           # Crush AI configs
â”‚   â”œâ”€â”€ .gemini/          # Gemini configs
â”‚   â”œâ”€â”€ .ollama/          # Ollama configs
â”‚   â”œâ”€â”€ .lmstudio/        # LM Studio configs
â”‚   â”œâ”€â”€ .qwen/            # Qwen configs
â”‚   â”œâ”€â”€ .opencode/        # OpenCode configs
â”‚   â”œâ”€â”€ .venv/            # Shared Python environment (CUDA libs)
â”‚   â”œâ”€â”€ .env              # Shared API keys
â”‚   â””â”€â”€ CLAUDE.md         # Claude-specific notes
â”œâ”€â”€ workspaces/           # Sandboxed work directories
â”‚   â”œâ”€â”€ claude/           # Claude Code workspace
â”‚   â”œâ”€â”€ crush/            # Crush workspace
â”‚   â”œâ”€â”€ gemini/           # Gemini workspace
â”‚   â”œâ”€â”€ ollama/           # Ollama workspace
â”‚   â”œâ”€â”€ lmstudio/         # LM Studio workspace
â”‚   â”œâ”€â”€ qwen/             # Qwen workspace
â”‚   â”œâ”€â”€ opencode/         # OpenCode workspace
â”‚   â””â”€â”€ scratch/          # Temporary work
â”œâ”€â”€ models/               # Shared AI models (13GB)
â”‚   â”œâ”€â”€ checkpoints/      # SD checkpoints (13GB)
â”‚   â”œâ”€â”€ loras/            # LoRA models
â”‚   â”œâ”€â”€ vae/              # VAE models
â”‚   â””â”€â”€ embeddings/       # Textual inversion
â”œâ”€â”€ stable-diffusion-webui/  # SD WebUI installation (9.3GB)
â””â”€â”€ scripts/              # Automation & launcher scripts
    â”œâ”€â”€ setup-tool-access.sh
    â”œâ”€â”€ load-env.sh
    â”œâ”€â”€ launch-claude.sh
    â”œâ”€â”€ launch-crush.sh
    â”œâ”€â”€ launch-gemini.sh
    â”œâ”€â”€ launch-ollama.sh
    â”œâ”€â”€ launch-lmstudio.sh
    â”œâ”€â”€ launch-qwen.sh
    â””â”€â”€ launch-opencode.sh
```

## Configuration Philosophy

**Sandbox with Filesystem Access:**
- Tools operate in dedicated workspaces under `~/Projects/ai/workspaces/`
- Full read/write access to most of the filesystem for troubleshooting
- Specific exclusions for safety (system files, other users)
- Auto-run capabilities for scripts and workflows

## Tool Configuration

### Claude Code
**Config Location:** `~/Projects/ai/configs/.claude/`
**Workspace:** `~/Projects/ai/workspaces/claude/`
**Settings:**
```json
{
  "workingDirectory": "/home/yish/Projects/ai/workspaces/claude",
  "allowedPaths": [
    "/home/yish/Projects",
    "/home/yish/Documents",
    "/home/yish/.config",
    "/tmp"
  ],
  "blockedPaths": [
    "/etc/shadow",
    "/etc/passwd",
    "/root"
  ]
}
```

### Crush
**Config Location:** `~/Projects/ai/configs/.crush/`
**Workspace:** `~/Projects/ai/workspaces/crush/`

### Gemini
**Config Location:** `~/Projects/ai/configs/.gemini/`
**Workspace:** `~/Projects/ai/workspaces/gemini/`
**Command:** `/usr/bin/gemini`

### Ollama
**Config Location:** `~/Projects/ai/configs/.ollama/`
**Workspace:** `~/Projects/ai/workspaces/ollama/`
**Command:** `/usr/bin/ollama`
**Models:** Stored in `~/.ollama/models` (20GB)

### LM Studio
**Config Location:** `~/Projects/ai/configs/.lmstudio/`
**Workspace:** `~/Projects/ai/workspaces/lmstudio/`
**Original Config:** `~/.lmstudio/`

### Qwen
**Config Location:** `~/Projects/ai/configs/.qwen/`
**Workspace:** `~/Projects/ai/workspaces/qwen/`
**Original Config:** `~/.qwen/`

### OpenCode
**Config Location:** `~/Projects/ai/configs/.opencode/`
**Workspace:** `~/Projects/ai/workspaces/opencode/`
**Original Config:** `~/.opencode/`

### Shared Resources
**Python Environment:** `~/Projects/ai/configs/.venv/`
- CUDA libraries for GPU acceleration
- Shared across all Python-based AI tools
- 9.2GB (NVIDIA CUDA libs)

**API Keys:** `~/Projects/ai/configs/.env`
- Gemini, Anthropic, OpenAI, X.AI, DeepSeek, DashScope
- Source this file in tool configs

## Filesystem Access Rules

### Read Access (Full)
- `/home/yish/` (all user files)
- `/tmp/` (temporary files)
- `/opt/` (optional software)

### Write Access (Controlled)
- `~/Projects/ai/workspaces/<tool>/` (primary workspace)
- `~/Projects/` (for project modifications)
- `~/Documents/` (for documentation)
- `/tmp/` (temporary files)

### Blocked
- `/etc/shadow`, `/etc/passwd` (system auth)
- `/root/` (root user home)
- `/sys/`, `/proc/` (kernel interfaces)
- Other user home directories

## Quick Launch Commands

All tools can be launched using their respective launcher scripts:

```bash
# Claude Code
~/Projects/ai/scripts/launch-claude.sh

# Crush AI
~/Projects/ai/scripts/launch-crush.sh

# Gemini
~/Projects/ai/scripts/launch-gemini.sh

# Ollama
~/Projects/ai/scripts/launch-ollama.sh
~/Projects/ai/scripts/launch-ollama.sh run llama2  # Interactive chat
~/Projects/ai/scripts/launch-ollama.sh list        # List installed models

# LM Studio
~/Projects/ai/scripts/launch-lmstudio.sh

# Qwen
~/Projects/ai/scripts/launch-qwen.sh

# OpenCode
~/Projects/ai/scripts/launch-opencode.sh
```

## Manual Usage Examples

### Claude Code
```bash
# Start Claude with AI hub context
cd ~/Projects/ai/workspaces/claude
source ~/Projects/ai/scripts/load-env.sh
claude --context ~/Projects/ai
```

### Crush
```bash
# Start Crush with shared config
cd ~/Projects/ai/workspaces/crush
source ~/Projects/ai/scripts/load-env.sh
crush --config ~/Projects/ai/configs/.crush/config.json
```

### Ollama
```bash
# Start Ollama in workspace
cd ~/Projects/ai/workspaces/ollama
source ~/Projects/ai/scripts/load-env.sh
ollama run deepseek-coder  # Use any installed model
```

### Gemini
```bash
# Start Gemini CLI
cd ~/Projects/ai/workspaces/gemini
source ~/Projects/ai/scripts/load-env.sh
gemini
```

## TUI Management Console

**Quick Start:**
```bash
# Launch the interactive TUI
~/Projects/ai/ai-hub
```

**Features:**
- ğŸ“Š Real-time system hardware monitoring (CPU, RAM, GPU, VRAM, Disk)
- ğŸ› ï¸ Tool status dashboard (7 AI tools tracked)
- ğŸ“¦ Model management with requirements checking
- ğŸ’¾ Storage breakdown and analysis
- ğŸš€ Interactive tool launcher
- âš ï¸ Pre-download hardware verification (prevents downloading incompatible models)

**See detailed guide:** [TUI-GUIDE.md](TUI-GUIDE.md)

## Benefits

1. **Centralized Configuration:** All AI tools share API keys and base configs
2. **Workspace Isolation:** Each tool has its own sandbox
3. **Filesystem Access:** Tools can troubleshoot and modify files across your system
4. **Auto-Run Capability:** Scripts can execute in workspaces with full context
5. **Easy Cleanup:** Clear separation of tool data
6. **Hardware Verification:** Check system requirements before downloading models
7. **Visual Management:** Beautiful TUI for monitoring and control

## Maintenance

### Clean Workspaces
```bash
# Remove temporary files from all workspaces
find ~/Projects/ai/workspaces -name "*.tmp" -delete
```

### Update API Keys
```bash
# Edit shared environment
nano ~/Projects/ai/configs/.env
```

### Rebuild Python Environment
```bash
cd ~/Projects/ai/configs
rm -rf .venv
python -m venv .venv
source .venv/bin/activate
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

**Last Updated:** 2025-12-31
