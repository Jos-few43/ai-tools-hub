# ğŸ¤– AI Tools Hub

> A unified management system for AI CLI tools with beautiful TUI, shared model storage, and CLI orchestration for chaining AI workflows.

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Platform: Linux](https://img.shields.io/badge/platform-linux-lightgrey.svg)](https://www.linux.org/)

## âœ¨ Features

- ğŸ–¥ï¸ **Beautiful TUI** - Interactive terminal interface for managing AI tools
- ğŸ”— **CLI Orchestration** - Chain and pipe commands across different AI tools *(coming soon)*
- ğŸ“Š **Hardware Monitoring** - Real-time CPU, RAM, GPU, VRAM tracking
- ğŸ” **Requirements Checker** - Verify system specs before downloading models
- ğŸ—‚ï¸ **Shared Model Storage** - No duplicate models across tools (save 50GB+)
- ğŸš€ **Unified Launcher** - Launch all AI tools from one interface
- ğŸ” **Centralized Configs** - Shared API keys and environment management
- ğŸ“¦ **7 Tool Support** - Claude Code, Ollama, Gemini, Crush, LM Studio, Qwen, OpenCode
- ğŸ’¾ **Storage Analytics** - Track and optimize disk usage

## ğŸ¯ Quick Start

```bash
# Clone the repository
git clone https://github.com/yourusername/ai-tools-hub.git
cd ai-tools-hub

# Run installation
./install.sh

# Launch the TUI
ai
```

## ğŸ”— CLI Orchestration Vision

Chain AI tools together like Unix pipes:

```bash
# Code review workflow
cat code.py | ai-hub claude review | ai-hub gemini improve | tee improved.py

# Multi-model consensus
echo "Is this a good idea?" | ai-hub ask --all | ai-hub compare

# Image generation pipeline
ai-hub ollama "Generate SD prompt for sunset" | ai-hub sd-gen | ai-hub upscale

# Document processing
cat report.txt | ai-hub summarize | ai-hub translate --to=spanish | ai-hub tts
```

See [Roadmap](#-roadmap) for implementation plan.

## ğŸ¨ Why AI Hub?

### Before
- âŒ Duplicate models wasting 50GB+
- âŒ Scattered configurations
- âŒ No hardware verification before downloads
- âŒ Manual tool management
- âŒ No way to chain AI tools

### After
- âœ… Shared models (one copy, multiple tools)
- âœ… Centralized configuration
- âœ… Pre-download hardware checks
- âœ… Beautiful TUI management
- âœ… CLI orchestration *(coming soon)*
- âœ… **90GB+ saved in testing**

## ğŸ› ï¸ Supported Tools

| Tool | Status | Description |
|------|--------|-------------|
| **Claude Code** | âœ… | Official Claude CLI |
| **Ollama** | âœ… | Local LLM runner |
| **Gemini** | âœ… | Google's Gemini CLI |
| **Crush** | âœ… | AI coding assistant |
| **LM Studio** | âœ… | Local model interface |
| **Qwen** | âœ… | Alibaba's Qwen models |
| **OpenCode** | âœ… | Open-source coding AI |
| **SD WebUI** | âœ… | Stable Diffusion WebUI |

## ğŸ’» System Requirements

### Minimum
- **OS:** Linux (Arch, Ubuntu, Debian, etc.)
- **Python:** 3.10+
- **Disk:** 50GB+ free
- **RAM:** 8GB

### Recommended
- **RAM:** 16GB+
- **GPU:** NVIDIA with 8GB+ VRAM
- **Disk:** 100GB+ free

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourusername/ai-tools-hub.git
cd ai-tools-hub
chmod +x install.sh
./install.sh
```

The installer will:
1. Create directory structure
2. Install dependencies (`python-rich`)
3. Set up bash aliases (`ai`, `ai-status`, etc.)
4. Configure API key template
5. Make scripts executable

## ğŸš€ Usage

### TUI Interface
```bash
ai                 # Launch interactive TUI
ai-status          # Quick status check
ai-models          # List all models
```

### Launch Tools
```bash
~/Projects/ai/scripts/launch-claude.sh
~/Projects/ai/scripts/launch-ollama.sh run llama2
~/Projects/ai/scripts/launch-sd-webui.sh
```

## ğŸ“š Documentation

- **[Getting Started](GETTING-STARTED.md)** - New user guide
- **[TUI Guide](TUI-GUIDE.md)** - Detailed TUI documentation
- **[Quick Reference](QUICK-REFERENCE.md)** - Command cheatsheet
- **[Architecture](ARCHITECTURE.md)** - System architecture

## ğŸ¯ Key Features

### Hardware Requirements Checker

Check before downloading:

```
ai â†’ [3] Model Management â†’ [2] Check requirements

Your System:
  RAM: 10GB   âš ï¸  (Need 16GB)
  VRAM: 6GB   âš ï¸  (Need 12GB)
  Disk: 100GB âœ…  (Need 24GB)

Result: Cannot run FLUX Dev
```

### Shared Model Storage

No more duplicates:

```
~/Projects/ai/models/checkpoints/model.safetensors (13GB)
    â†“ (symlinked to both)
    â”œâ”€â†’ ComfyUI/models/
    â””â”€â†’ SD-WebUI/models/

Before: 26GB | After: 13GB | Saved: 13GB
```

### Real-Time Monitoring

```
â•­â”€â”€â”€â”€â”€â”€ Quick Stats â”€â”€â”€â”€â”€â”€â•®
â”‚ Hub:  31GB              â”‚
â”‚ RAM:  10GB available    â”‚
â”‚ GPU:  RTX 3060 (6GB)    â”‚
â”‚ Disk: 100GB free        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

## ğŸ“Š Performance

**Space Savings in Testing:**
- Consolidated models: +45GB
- Cleaned caches: +34GB
- Removed unused: +1.4GB
- Emptied trash: +9.3GB
- **Total: 90.1GB saved** âœ¨

| Directory | Before | After | Saved |
|-----------|--------|-------|-------|
| ComfyUI | 112GB | 22GB | 90GB |
| Projects | 10GB | 651MB | 9.3GB |
| AI Hub | 9GB | 31GB | -22GB |
| **Total** | **131GB** | **54GB** | **77GB** |

## ğŸ—ºï¸ Roadmap

### Phase 1: CLI Orchestration ğŸ¯ *(Next Priority)*

**Core Framework**
- [ ] Unified `ai-hub` command with subcommands
- [ ] Standard I/O format (JSON/streaming)
- [ ] Error handling and status codes

**Tool Wrappers**
- [ ] `ai-hub ask <tool> <prompt>` - Universal interface
- [ ] `ai-hub compare <prompt>` - Multi-tool comparison
- [ ] Direct tool access: `ai-hub claude|gemini|ollama`

**Pipeline Features**
- [ ] Pipe chaining: `tool1 | tool2 | tool3`
- [ ] Parallel execution: `ai-hub parallel "prompt"`
- [ ] Template workflows: `ai-hub run workflow.yaml`
- [ ] Save/replay: `ai-hub save/replay <name>`

**Flow Playground**
- [ ] Interactive workflow builder (TUI)
- [ ] Pre-built templates (code review, translation, etc.)
- [ ] Workflow visualization
- [ ] Debug mode with step execution

### Phase 2: Enhanced Features
- [ ] Model download integration
- [ ] Cloud storage sync
- [ ] Workflow marketplace
- [ ] Remote execution

### Phase 3: Platform Support
- [ ] Web interface (optional)
- [ ] Docker containerization
- [ ] macOS support
- [ ] Windows WSL support

## ğŸ’¡ CLI Orchestration Use Cases

### Code Review Pipeline
```bash
cat app.py \
  | ai-hub claude "Review bugs" \
  | ai-hub gemini "Best practices" \
  | ai-hub ollama "Optimize" \
  | tee review.md
```

### Content Creation
```bash
echo "AI Tools" \
  | ai-hub claude "Blog outline" \
  | ai-hub gemini "Full post" \
  | ai-hub ollama "SEO keywords"
```

### Multi-Model Consensus
```bash
ai-hub compare-all "Refactor this?" \
  --tools claude,gemini,ollama \
  --format table
```

### Image Pipeline
```bash
echo "Sunset mountains" \
  | ai-hub ollama "SD prompt" \
  | ai-hub sd-gen --model realistic \
  | ai-hub upscale --2x
```

## ğŸ¤ Contributing

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md).

1. Fork the repository
2. Create feature branch (`git checkout -b feature/name`)
3. Commit changes (`git commit -m 'Add feature'`)
4. Push to branch (`git push origin feature/name`)
5. Open Pull Request

## ğŸ› Troubleshooting

**GPU Not Detected**
```bash
nvidia-smi  # Verify drivers
ai          # Restart TUI
```

**TUI Won't Launch**
```bash
pip install rich
# OR
sudo pacman -S python-rich
```

**Models Missing**
```bash
ls ~/Projects/ai/models/checkpoints/
# Should show .safetensors files
```

## ğŸ“„ License

Apache License 2.0 - see [LICENSE](LICENSE)

## ğŸ™ Acknowledgments

- [Rich](https://github.com/Textualize/rich) - Beautiful terminal UI
- AI Tools community
- All contributors

---

<p align="center">
  Made with â¤ï¸ by the AI Tools Hub community
</p>

<p align="center">
  <a href="https://github.com/yourusername/ai-tools-hub">GitHub</a> â€¢
  <a href="https://github.com/yourusername/ai-tools-hub/issues">Issues</a> â€¢
  <a href="https://github.com/yourusername/ai-tools-hub/discussions">Discussions</a>
</p>
